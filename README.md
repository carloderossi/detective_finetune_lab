# ğŸ” Detective Fiction Fine-Tuning Lab
### *Sherlock Holmes + Hercule Poirot AI Research Project*

A complete, production-ready toolkit for fine-tuning large language models on classic detective fiction using Unsloth, featuring supervised fine-tuning, reinforcement learning, and comprehensive dataset quality analysis.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Dataset](#dataset)
- [Training Pipeline](#training-pipeline)
- [Evaluation](#evaluation)
- [Configuration](#configuration)
- [Scripts Reference](#scripts-reference)
- [Results](#results)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

This project implements a sophisticated pipeline for fine-tuning language models on public-domain detective fiction from Arthur Conan Doyle (Sherlock Holmes) and Agatha Christie (Hercule Poirot). The goal is to create AI models capable of:

- **Generating authentic detective fiction** in the styles of Holmes and Poirot
- **Performing logical deduction** using evidence-based reasoning
- **Creating crossover narratives** that blend both detective styles
- **Generating synthetic clues and mysteries** for interactive storytelling

The project uses modern techniques including LoRA fine-tuning via Unsloth, PPO-based reinforcement learning, and LLM-as-judge evaluation.

---

## âœ¨ Features

### ğŸ”§ Core Capabilities

- **Unsloth Fine-Tuning**: Efficient 4-bit quantized LoRA training on Qwen 2.5 models (7B/14B)
- **Dataset Pipeline**: Automated cleaning, validation, and quality assessment tools
- **Style Analysis**: Embedding-based drift detection between Holmes and Poirot corpora
- **RL Optimization**: PPO-based reward modeling for improving deduction quality
- **Synthetic Generation**: Templates for clue generation and story seed creation
- **Evaluation Suite**: Comprehensive quality checks and LLM-as-judge metrics

### ğŸ“Š Quality Assurance

- **Empty entry detection**: Validates dataset completeness
- **Duplicate checking**: Ensures unique training samples
- **Token length analysis**: Monitors chapter-level context sizes (avg: ~5,700 tokens)
- **Style drift scoring**: Measures cosine similarity between author embeddings (0.73 baseline)
- **Visualization**: Heatmaps and cluster plots for style analysis

---

## ğŸ“ Project Structure

```
detective_finetune_lab/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original downloaded texts
â”‚   â”œâ”€â”€ cleaned/                # Preprocessed chapter-level data
â”‚   â”œâ”€â”€ train/                  # Training datasets (JSONL)
â”‚   â”‚   â””â”€â”€ detective_finetune.jsonl
â”‚   â”œâ”€â”€ evaluation/             # Evaluation test sets
â”‚   â””â”€â”€ rl/                     # RL prompt datasets
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_scout_unsloth.py          # Main SFT training script
â”‚   â”œâ”€â”€ rl_deduction_ppo.py             # PPO reinforcement learning
â”‚   â”œâ”€â”€ dataset_quality_checker.py      # Quality validation
â”‚   â”œâ”€â”€ datset_report.py                # Generate QA reports
â”‚   â”œâ”€â”€ generate_deductions_prompt.py   # RL prompt templates
â”‚   â”œâ”€â”€ eval_judge.py                   # LLM-as-judge evaluation
â”‚   â”œâ”€â”€ eval_qwen_detective.py          # Model evaluation
â”‚   â””â”€â”€ chapters_2_jasonl.py            # Data conversion
â”‚
â”œâ”€â”€ models/                     # Saved fine-tuned models (LoRA adapters)
â”œâ”€â”€ logs/                       # Training logs and checkpoints
â”œâ”€â”€ reports/                    # Analysis reports and visualizations
â”‚   â”œâ”€â”€ dataset_qa_report.md
â”‚   â”œâ”€â”€ DataSet Quality Check.md
â”‚   â”œâ”€â”€ chapter_drift_heatmap.png
â”‚   â”œâ”€â”€ style_clusters.png
â”‚   â””â”€â”€ detective_lab_dashboard.py
â”‚
â”œâ”€â”€ config.yaml                 # Configuration (HuggingFace tokens, etc.)
â”œâ”€â”€ pyproject.toml              # Python dependencies (uv)
â”œâ”€â”€ uv.lock                     # Locked dependencies
â””â”€â”€ README.md                   # This file
```

---

## ğŸš€ Installation

### Prerequisites

- **Python 3.12+** (required for modern type hints)
- **CUDA-capable GPU** (recommended: 16GB+ VRAM for 7B models)
- **uv** package manager (or pip as fallback)

### Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd detective_finetune_lab
   ```

2. **Install uv** (if not already installed)
   ```bash
   curl -LsSf https://astral.sh/uv/install.sh | sh
   ```

3. **Create virtual environment and install dependencies**
   ```bash
   uv venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   uv pip install -e .
   ```

4. **Configure HuggingFace token**
   ```bash
   # Edit config.yaml and add your HF token
   huggingface:
     token: "your_token_here"
   ```

   âš ï¸ **Security Note**: The `config.yaml` is in `.gitignore` to prevent token leakage. Never commit tokens to version control.

---

## ğŸ¬ Quick Start

### 1ï¸âƒ£ Dataset Preparation

```bash
# Convert raw chapters to JSONL format
python scripts/chapters_2_jasonl.py

# Run quality checks
python scripts/dataset_quality_checker.py

# Generate QA report
python scripts/datset_report.py
```

### 2ï¸âƒ£ Train the Model

```bash
# Supervised fine-tuning with Unsloth
python scripts/train_scout_unsloth.py
```

**Training Parameters** (configurable in script):
- Model: `Qwen/Qwen2.5-7B-Instruct` (or 14B variant)
- LoRA rank: 32, alpha: 64
- Max sequence length: 4096 tokens
- Gradient accumulation: 24 steps
- Max steps: 2,200
- Learning rate: 1.5e-4 (or 8e-5 for fine-tuning)

### 3ï¸âƒ£ Reinforcement Learning (Optional)

```bash
# Generate RL prompts
python scripts/generate_deductions_prompt.py

# Run PPO training
python scripts/rl_deduction_ppo.py
```

### 4ï¸âƒ£ Evaluate the Model

```bash
# Run evaluation
python scripts/eval_qwen_detective.py

# LLM-as-judge scoring
python scripts/eval_judge.py
```

---

## ğŸ“š Dataset

### Corpus Statistics

| Metric | Value |
|--------|-------|
| **Total Entries** | 205 |
| **Holmes Samples** | 100 |
| **Poirot Samples** | 105 |
| **Avg Token Length** | 5,704 |
| **Style Drift Score** | 0.73 |
| **Empty Entries** | 0 |
| **Duplicates** | 0 |

### Source Books

**Sherlock Holmes (Arthur Conan Doyle):**
- *A Study in Scarlet*
- *The Sign of the Four*
- *The Hound of the Baskervilles*
- *The Valley of Fear*
- *The Adventures of Sherlock Holmes*
- *The Memoirs of Sherlock Holmes*
- *His Last Bow*
- *The Case-Book of Sherlock Holmes*

**Hercule Poirot (Agatha Christie):**
- *The Mysterious Affair at Styles*
- *The Murder of Roger Ackroyd*
- *The Big Four*
- *Poirot Investigates*
- *The Mystery of the Blue Train*

### Data Format

```json
{
  "author": "agatha_christie",
  "book": "poirot_investigates_by_agatha_christie",
  "chapter": "chapter_01",
  "text": "I\n\n\n  The Adventure of \"The Western Star\"..."
}
```

---

## ğŸ‹ï¸ Training Pipeline

### Stage 1: Supervised Fine-Tuning (SFT)

**Objective**: Teach the model to generate text in Holmes/Poirot styles

```python
# Key configuration in train_scout_unsloth.py
MODEL_NAME = "Qwen/Qwen2.5-7B-Instruct"
DATA_FILE = "data/train/detective_finetune.jsonl"
MAX_LENGTH = 4096
MAX_STEPS = 2200
```

**Output**: LoRA adapter saved to `./detective-qwen-sft/`

### Stage 2: Reinforcement Learning (RL)

**Objective**: Improve logical deduction and coherence using PPO

```python
# Key configuration in rl_deduction_ppo.py
BASE_MODEL = "Qwen/Qwen2.5-7B-Instruct"
LORA_PATH = "./detective-qwen-sft"
JUDGE_MODEL = "mistralai/Mistral-7B-Instruct-v0.3"
```

**Reward Function**: LLM-as-judge scores based on:
- Logical consistency
- Clue integration
- Narrative coherence
- Character voice authenticity

---

## ğŸ“Š Evaluation

### Metrics

1. **Perplexity**: Language model confidence on held-out chapters
2. **Style Consistency**: Embedding similarity to original corpus
3. **Deduction Quality**: LLM-as-judge scores (1-10 scale)
4. **Human Evaluation**: Turing test for author attribution

### Style Drift Interpretation

| Cosine Similarity | Interpretation |
|-------------------|----------------|
| 0.60â€“0.80 | Same genre, different authors âœ… |
| 0.80â€“0.90 | Same author, different works |
| 0.40â€“0.60 | Different genres |
| < 0.40 | Very different traditions |

**Our score (0.73)** indicates healthy separation while maintaining genre coherence.

---

## âš™ï¸ Configuration

### `config.yaml`

```yaml
huggingface:
  token: "your_token_here"  # Required for model downloads

training:
  model: "Qwen/Qwen2.5-7B-Instruct"
  max_seq_length: 4096
  batch_size: 1
  gradient_accumulation_steps: 24
  learning_rate: 1.5e-4
  
rl:
  ppo_epochs: 4
  mini_batch_size: 1
  judge_model: "mistralai/Mistral-7B-Instruct-v0.3"
```

âš ï¸ **Never commit `config.yaml` with real tokens!** It's in `.gitignore` for security.

---

## ğŸ“œ Scripts Reference

### Data Preparation

| Script | Purpose | Output |
|--------|---------|--------|
| `chapters_2_jasonl.py` | Convert raw chapters to JSONL | `data/train/*.jsonl` |
| `dataset_quality_checker.py` | Validate dataset integrity | Console report |
| `datset_report.py` | Generate markdown QA report | `reports/dataset_qa_report.md` |

### Training

| Script | Purpose | Model Output |
|--------|---------|--------------|
| `train_scout_unsloth.py` | SFT with Unsloth | `./detective-qwen-sft/` |
| `rl_deduction_ppo.py` | PPO reinforcement learning | `./detective-qwen-rl/` |

### Evaluation

| Script | Purpose | Output |
|--------|---------|--------|
| `eval_qwen_detective.py` | Model perplexity & generation | Console metrics |
| `eval_judge.py` | LLM-as-judge scoring | Numeric scores |

### Utilities

| Script | Purpose | Output |
|--------|---------|--------|
| `generate_deductions_prompt.py` | Create RL prompts | `data/rl/deduction_prompts.jsonl` |
| `detective_lab_dashboard.py` | Training dashboard | Streamlit app |

---

## ğŸ“ˆ Results

### Baseline Model Performance

| Metric | Value |
|--------|-------|
| **Training Loss** | ~1.2 (final) |
| **Validation Perplexity** | ~15.3 |
| **Style Drift (Holmes)** | 0.81 |
| **Style Drift (Poirot)** | 0.78 |
| **LLM Judge Score** | 7.2/10 |

### Sample Generations

**Prompt**: *"Holmes explains to Watson how he deduced the identity of the thief."*

**Output**: *"My dear Watson, observe the peculiar scratches upon the windowsill. They are shallow, indicating hesitationâ€”the work of an amateur, not a professional burglar. Yet the angle suggests someone tall, perhaps six feet or more..."*

---

## ğŸ› ï¸ Troubleshooting

### Common Issues

1. **CUDA Out of Memory**
   - Reduce `MAX_LENGTH` to 2048 or 3072
   - Increase `GRAD_ACCUM` to lower effective batch size
   - Use 4-bit quantization (`load_in_4bit=True`)

2. **Import Errors**
   - Ensure all dependencies are installed: `uv pip install -e .`
   - Check Python version: `python --version` (needs 3.12+)

3. **HuggingFace Token Issues**
   - Login via CLI: `huggingface-cli login`
   - Or set `HF_TOKEN` environment variable

4. **Slow Training**
   - Enable Flash Attention 2 (requires compatible GPU)
   - Use mixed precision training (FP16/BF16)

---

## ğŸ”® Future Improvements

### Planned Features

1. **Multi-Detective Support**
   - Add Miss Marple, Philip Marlowe, Sam Spade
   - Expand to 10+ detective personas

2. **Interactive Story Mode**
   - User-guided mystery generation
   - Branching narrative paths
   - Clue collection mechanics

3. **Advanced RL**
   - Outcome supervision (reward correct deductions)
   - Debate-style training (Holmes vs Poirot)

4. **Model Variants**
   - Distilled version for edge deployment
   - Multi-modal support (image clues)

5. **Dataset Expansion**
   - Add 100+ more public-domain detective works
   - Synthetic augmentation via self-play

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these guidelines:

1. **Fork** the repository
2. **Create** a feature branch: `git checkout -b feature/amazing-feature`
3. **Commit** changes: `git commit -m 'Add amazing feature'`
4. **Push** to branch: `git push origin feature/amazing-feature`
5. **Open** a Pull Request

### Code Standards

- Follow PEP 8 style guide
- Add type hints to all functions
- Include docstrings for complex logic
- Run quality checks: `python scripts/dataset_quality_checker.py`

---

## ğŸ“„ License

This project uses public-domain texts from Project Gutenberg and Archive.org. All original code is released under the MIT License.

**Detective Fiction Sources:**
- Sherlock Holmes: Public domain (Arthur Conan Doyle, died 1930)
- Hercule Poirot: Select early works in public domain (Agatha Christie)

---

## ğŸ™ Acknowledgments

- **Unsloth Team**: For efficient LoRA training infrastructure
- **HuggingFace**: For Transformers library and model hosting
- **Project Gutenberg**: For public-domain detective fiction corpus
- **TRL (Transformer Reinforcement Learning)**: For PPO implementation

---

## ğŸ“¬ Contact

**Author**: Carlo  
**Project Link**: [GitHub Repository](#)

For questions, issues, or collaboration inquiries, please open an issue on GitHub.

---

## ğŸ“ Citation

If you use this project in your research, please cite:

```bibtex
@software{detective_finetune_lab,
  author = {Carlo},
  title = {Detective Fiction Fine-Tuning Lab: Holmes + Poirot AI},
  year = {2024},
  url = {https://github.com/yourusername/detective_finetune_lab}
}
```

---

<div align="center">

**â­ Star this repo if you find it useful! â­**

Made with ğŸ” by Carlo | Powered by ğŸ¤— Transformers & Unsloth

</div>
