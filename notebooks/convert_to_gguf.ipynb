{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 28 18:33:23 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   56C    P0             29W /   70W |     155MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1712      C   /usr/bin/python3                        152MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 195715,
     "status": "ok",
     "timestamp": 1771191226822,
     "user": {
      "displayName": "Carlo Carlo",
      "userId": "11471837763026793486"
     },
     "user_tz": -60
    },
    "id": "EvPeuYNuaD3-",
    "outputId": "e338b91a-ea9a-473c-98b7-b5013963fe46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: unsloth 2026.2.1\n",
      "Uninstalling unsloth-2026.2.1:\n",
      "  Successfully uninstalled unsloth-2026.2.1\n",
      "Found existing installation: unsloth_zoo 2026.2.1\n",
      "Uninstalling unsloth_zoo-2026.2.1:\n",
      "  Successfully uninstalled unsloth_zoo-2026.2.1\n",
      "Found existing installation: transformers 4.57.6\n",
      "Uninstalling transformers-4.57.6:\n",
      "  Successfully uninstalled transformers-4.57.6\n",
      "Found existing installation: accelerate 1.12.0\n",
      "Uninstalling accelerate-1.12.0:\n",
      "  Successfully uninstalled accelerate-1.12.0\n",
      "Found existing installation: peft 0.18.1\n",
      "Uninstalling peft-0.18.1:\n",
      "  Successfully uninstalled peft-0.18.1\n",
      "Found existing installation: datasets 4.3.0\n",
      "Uninstalling datasets-4.3.0:\n",
      "  Successfully uninstalled datasets-4.3.0\n",
      "Found existing installation: tokenizers 0.22.2\n",
      "Uninstalling tokenizers-0.22.2:\n",
      "  Successfully uninstalled tokenizers-0.22.2\n",
      "Found existing installation: huggingface_hub 0.36.2\n",
      "Uninstalling huggingface_hub-0.36.2:\n",
      "  Successfully uninstalled huggingface_hub-0.36.2\n",
      "Found existing installation: bitsandbytes 0.49.2\n",
      "Uninstalling bitsandbytes-0.49.2:\n",
      "  Successfully uninstalled bitsandbytes-0.49.2\n",
      "Found existing installation: sentencepiece 0.2.1\n",
      "Uninstalling sentencepiece-0.2.1:\n",
      "  Successfully uninstalled sentencepiece-0.2.1\n",
      "Found existing installation: trl 0.24.0\n",
      "Uninstalling trl-0.24.0:\n",
      "  Successfully uninstalled trl-0.24.0\n",
      "Found existing installation: xformers 0.0.35\n",
      "Uninstalling xformers-0.0.35:\n",
      "  Successfully uninstalled xformers-0.0.35\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.10.0+cu128)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch) (1.3.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Collecting unsloth==2026.2.1\n",
      "  Using cached unsloth-2026.2.1-py3-none-any.whl.metadata (69 kB)\n",
      "Collecting unsloth_zoo>=2026.2.1 (from unsloth==2026.2.1)\n",
      "  Using cached unsloth_zoo-2026.2.1-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (0.46.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (26.0)\n",
      "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (2.10.0+cu128)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (0.25.0+cu128)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (2.0.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (4.67.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (5.9.5)\n",
      "Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (1.0.8)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (5.29.6)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth==2026.2.1)\n",
      "  Using cached xformers-0.0.35-py39-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth==2026.2.1)\n",
      "  Using cached bitsandbytes-0.49.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (3.6.0)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth==2026.2.1)\n",
      "  Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth==2026.2.1)\n",
      "  Using cached datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting accelerate>=0.34.1 (from unsloth==2026.2.1)\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft!=0.11.0,>=0.18.0 (from unsloth==2026.2.1)\n",
      "  Using cached peft-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth==2026.2.1)\n",
      "  Using cached huggingface_hub-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth==2026.2.1) (0.36.0)\n",
      "Collecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3 (from unsloth==2026.2.1)\n",
      "  Using cached transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth==2026.2.1)\n",
      "  Using cached trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth==2026.2.1) (6.0.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth==2026.2.1) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (3.24.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (23.0.1)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (2.32.4)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth==2026.2.1) (1.3.0)\n",
      "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth==2026.2.1) (0.24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth==2026.2.1) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2026.2.1) (1.13.1.3)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.4.0->unsloth==2026.2.1) (1.3.5)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth==2026.2.1)\n",
      "  Using cached huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth==2026.2.1) (2025.11.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth==2026.2.1)\n",
      "  Using cached tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: torchao>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.2.1->unsloth==2026.2.1) (0.16.0)\n",
      "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.2.1->unsloth==2026.2.1) (25.1.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.2.1->unsloth==2026.2.1) (11.3.0)\n",
      "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.2.1->unsloth==2026.2.1) (0.20.0)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth==2026.2.1) (8.7.1)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth==2026.2.1) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth==2026.2.1) (4.5.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (3.13.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth==2026.2.1) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth==2026.2.1) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth==2026.2.1) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth==2026.2.1) (1.17.0)\n",
      "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer->huggingface_hub>=0.34.0->unsloth==2026.2.1) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->huggingface_hub>=0.34.0->unsloth==2026.2.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->huggingface_hub>=0.34.0->unsloth==2026.2.1) (13.9.4)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer->huggingface_hub>=0.34.0->unsloth==2026.2.1) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer->huggingface_hub>=0.34.0->unsloth==2026.2.1) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer->huggingface_hub>=0.34.0->unsloth==2026.2.1) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer->huggingface_hub>=0.34.0->unsloth==2026.2.1) (0.1.2)\n",
      "Using cached unsloth-2026.2.1-py3-none-any.whl (432 kB)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Using cached bitsandbytes-0.49.2-py3-none-manylinux_2_24_x86_64.whl (60.7 MB)\n",
      "Using cached datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Using cached peft-0.18.1-py3-none-any.whl (556 kB)\n",
      "Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "Using cached transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
      "Using cached trl-0.24.0-py3-none-any.whl (423 kB)\n",
      "Using cached unsloth_zoo-2026.2.1-py3-none-any.whl (376 kB)\n",
      "Using cached xformers-0.0.35-py39-none-manylinux_2_28_x86_64.whl (3.3 MB)\n",
      "Using cached tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Installing collected packages: sentencepiece, huggingface_hub, tokenizers, xformers, transformers, datasets, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth\n",
      "Successfully installed accelerate-1.12.0 bitsandbytes-0.49.2 datasets-4.3.0 huggingface_hub-0.36.2 peft-0.18.1 sentencepiece-0.2.1 tokenizers-0.22.2 transformers-4.57.6 trl-0.24.0 unsloth-2026.2.1 unsloth_zoo-2026.2.1 xformers-0.0.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "1058f39b2e7c4b5c8dd35726b5f022b6",
       "pip_warning": {
        "packages": [
         "accelerate",
         "bitsandbytes",
         "datasets",
         "huggingface_hub",
         "peft",
         "tokenizers",
         "transformers",
         "trl",
         "unsloth",
         "unsloth_zoo",
         "xformers"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth_zoo@ git+https://github.com/unslothai/unsloth-zoo.git@February-2026\n",
      "  Cloning https://github.com/unslothai/unsloth-zoo.git (to revision February-2026) to /tmp/pip-install-b1t0iof9/unsloth-zoo_76b2063ae5c94dd3a4b2df9f8fa418b7\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth-zoo.git /tmp/pip-install-b1t0iof9/unsloth-zoo_76b2063ae5c94dd3a4b2df9f8fa418b7\n",
      "\u001b[33m  WARNING: Did not find branch or tag 'February-2026', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running command git checkout -q February-2026\n",
      "  error: pathspec 'February-2026' did not match any file(s) known to git\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mgit checkout -q February-\u001b[0m\u001b[1;32m2026\u001b[0m did not run successfully.\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31mÃ—\u001b[0m \u001b[32mgit checkout -q February-\u001b[0m\u001b[1;32m2026\u001b[0m did not run successfully.\n",
      "\u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "Requirement already satisfied: transformers<4.58.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: peft>=0.18.0 in /usr/local/lib/python3.12/dist-packages (0.18.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.3.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.2)\n",
      "Requirement already satisfied: trl<0.25.0 in /usr/local/lib/python3.12/dist-packages (0.24.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.57.0) (3.24.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.57.0) (0.36.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.57.0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.57.0) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.57.0) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.57.0) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.57.0) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.57.0) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.57.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.57.0) (4.67.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1) (2.10.0+cu128)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (23.0.1)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<4.58.0,>=4.57.0) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<4.58.0,>=4.57.0) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<4.58.0,>=4.57.0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<4.58.0,>=4.57.0) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.1) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.0.0->accelerate>=0.34.1) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.34.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.1) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# --- CLEAN START ---\n",
    "# Remove everything that can conflict\n",
    "# !pip uninstall -y unsloth unsloth-zoo transformers accelerate peft datasets tokenizers huggingface-hub bitsandbytes sentencepiece\n",
    "\n",
    "# --- PYTORCH (CUDA 11.8) ---\n",
    "# !pip install torch --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# --- INSTALL MODERN UNSLOTH (the correct one for Qwen2.5) ---\n",
    "# !pip install \"unsloth==2026.2.1\"\n",
    "\n",
    "# --- INSTALL THE HF STACK COMPATIBLE WITH UNSLOTH 2026.x ---\n",
    "# !pip install \"transformers>=4.57.0\" \"accelerate>=0.34.1\" \"peft>=0.18.0\" datasets sentencepiece bitsandbytes\n",
    "\n",
    "# Clean uninstall - remove everything that could conflict\n",
    "!pip uninstall -y unsloth unsloth-zoo transformers accelerate peft datasets tokenizers huggingface-hub bitsandbytes sentencepiece trl xformers\n",
    "\n",
    "# Install pinned PyTorch for CUDA 11.8 (good for T4)\n",
    "!pip install torch --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install exact Unsloth 2026.2.1 release\n",
    "!pip install \"unsloth==2026.2.1\"\n",
    "\n",
    "# Force-reinstall unsloth_zoo right after to match the 2026.2.1 expectations\n",
    "!pip install --no-cache-dir --force-reinstall \"unsloth_zoo @ git+https://github.com/unslothai/unsloth-zoo.git@February-2026\"\n",
    "\n",
    "# Compatible HF ecosystem versions (your original bounds are fine, but explicit helps)\n",
    "!pip install \"transformers>=4.57.0,<4.58.0\" \"accelerate>=0.34.1\" \"peft>=0.18.0\" \"datasets\" \"sentencepiece\" \"bitsandbytes\" \"trl<0.25.0\"\n",
    "\n",
    "##########################################\n",
    "# 1. Install Unsloth with the latest Colab-specific optimization\n",
    "# !pip install --force-reinstall --no-cache-dir --no-deps \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "# !pip install --no-cache-dir unsloth_zoo\n",
    "# Force-update both packages together to stay in sync\n",
    "# !pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "# !pip install --upgrade --no-cache-dir unsloth_zoo\n",
    "# !pip uninstall -y unsloth unsloth-zoo\n",
    "# !pip install --upgrade --no-cache-dir \"unsloth[colab-new]@git+https://github.com/unslothai/unsloth.git\"\n",
    "# !pip install --upgrade --no-cache-dir unsloth_zoo\n",
    "\n",
    "# 2. Install essential backends for LoRA and 4-bit quantization\n",
    "#!pip install --no-deps \"xformers<0.0.30\" \"trl<0.13.0\" peft accelerate bitsandbytes\n",
    "\n",
    "# 3. Install data handling and high-speed download utilities\n",
    "#!pip install datasets sentencepiece hf_transfer huggingface_hub\n",
    "\n",
    "# 4. Enable HF_TRANSFER for 10x faster model loading into Colab's local disk\n",
    "import os\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026.2.1\n",
      "2026.2.1\n",
      "Name: unsloth\n",
      "Version: 2026.2.1\n",
      "Location: /usr/local/lib/python3.12/dist-packages\n",
      "Name: unsloth_zoo\n",
      "Version: 2026.2.1\n",
      "Location: /usr/local/lib/python3.12/dist-packages\n"
     ]
    }
   ],
   "source": [
    "import unsloth; print(unsloth.__version__)\n",
    "import unsloth_zoo; print(unsloth_zoo.__version__ if hasattr(unsloth_zoo, '__version__') else \"no __version__ attr\")\n",
    "!pip show unsloth unsloth-zoo | grep -E \"Name|Version|Location\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2153,
     "status": "ok",
     "timestamp": 1771191228972,
     "user": {
      "displayName": "Carlo Carlo",
      "userId": "11471837763026793486"
     },
     "user_tz": -60
    },
    "id": "XxS1ftFIdXRp",
    "outputId": "fbff2aa2-43bb-40f0-919a-50083fbf33ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "HF_TOKEN is set in the environment.\n",
      "ğŸš€ Hardware: T4 (using FP16)\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import torch\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "with open('/content/drive/MyDrive/TMP/HF_TOKEN.txt') as f:\n",
    "    token = f.read().strip()\n",
    "    if token:\n",
    "        os.environ[\"HF_TOKEN\"] = token\n",
    "# 2. Check if HF_TOKEN is set in the environment\n",
    "test_token=os.getenv(\"HF_TOKEN\")\n",
    "if test_token:\n",
    "    print(\"HF_TOKEN is set in the environment.\")\n",
    "else:\n",
    "    print(\"HF_TOKEN is NOT set in the environment. Please check your token file and try again.\")\n",
    "    raise ValueError(\"HF_TOKEN not found in environment variables.\")\n",
    "\n",
    "# 2. Detect Hardware for optimization\n",
    "major_v, _ = torch.cuda.get_device_capability()\n",
    "IS_A100 = True if major_v >= 8 else False\n",
    "print(f\"ğŸš€ Hardware: {'A100 (using BF16)' if IS_A100 else 'T4 (using FP16)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Script found: /content/drive/MyDrive/scripts/train_scout_unsloth.py\n",
      "âœ… Data found: /content/drive/MyDrive/data/train/detective_finetune.jsonl\n",
      "âœ… OutputFlder found: /content/drive/MyDrive/outputs/detective-qwen-sft\n",
      "âœ… GGUFOutputFlder found: /content/drive/MyDrive/models/detective-qwen-gguf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "paths = {\n",
    "    \"Script\": \"/content/drive/MyDrive/scripts/train_scout_unsloth.py\",\n",
    "    \"Data\": \"/content/drive/MyDrive/data/train/detective_finetune.jsonl\",\n",
    "    \"OutputFlder\": \"/content/drive/MyDrive/outputs/detective-qwen-sft\",\n",
    "    \"GGUFOutputFlder\": \"/content/drive/MyDrive/models/detective-qwen-gguf\"\n",
    "}\n",
    "\n",
    "for name, path in paths.items():\n",
    "    if os.path.exists(path):\n",
    "        print(f\"âœ… {name} found: {path}\")\n",
    "    else:\n",
    "        print(f\"âŒ {name} MISSING: {path}\")\n",
    "        raise FileNotFoundError(f\"{name} not found at {path}. Please check the path and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.3.16.tar.gz (50.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m211.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
      "  Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting jinja2>=2.11.3 (from llama-cpp-python)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n",
      "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m209.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m293.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m258.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m207.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.16-cp312-cp312-linux_x86_64.whl size=4422322 sha256=dcd35fc4d01c9f52b8c7502216709da74e3784580066092b508e1801ff0bc7ad\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-f1_czbaq/wheels/90/82/ab/8784ee3fb99ddb07fd36a679ddbe63122cc07718f6c1eb3be8\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 3.0.3\n",
      "    Uninstalling MarkupSafe-3.0.3:\n",
      "      Successfully uninstalled MarkupSafe-3.0.3\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.6\n",
      "    Uninstalling Jinja2-3.1.6:\n",
      "      Successfully uninstalled Jinja2-3.1.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.2 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 diskcache-5.6.3 jinja2-3.1.6 llama-cpp-python-0.3.16 numpy-2.4.2 typing-extensions-4.15.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "184a8502fb44475892e299979e9bdf6b",
       "pip_warning": {
        "packages": [
         "markupsafe",
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 173271\n",
      "-rw------- 1 root root      1209 Feb 27 16:35 adapter_config.json\n",
      "-rw------- 1 root root 161533192 Feb 27 16:35 adapter_model.safetensors\n",
      "-rw------- 1 root root       605 Feb 27 16:35 added_tokens.json\n",
      "-rw------- 1 root root      2507 Feb 27 16:35 chat_template.jinja\n",
      "drwx------ 2 root root      4096 Feb 27 16:25 checkpoint-101\n",
      "drwx------ 2 root root      4096 Feb 27 16:35 checkpoint-120\n",
      "-rw------- 1 root root   1671853 Feb 27 16:35 merges.txt\n",
      "-rw------- 1 root root      5252 Feb 27 16:35 README.md\n",
      "-rw------- 1 root root       496 Feb 27 16:35 special_tokens_map.json\n",
      "-rw------- 1 root root      4709 Feb 27 16:35 tokenizer_config.json\n",
      "-rw------- 1 root root  11421896 Feb 27 16:17 tokenizer.json\n",
      "-rw------- 1 root root   2776833 Feb 27 16:35 vocab.json\n",
      "{\n",
      "  \"alora_invocation_tokens\": null,\n",
      "  \"alpha_pattern\": {},\n",
      "  \"arrow_config\": null,\n",
      "  \"auto_mapping\": {\n",
      "    \"base_model_class\": \"Qwen2ForCausalLM\",\n",
      "    \"parent_library\": \"transformers.models.qwen2.modeling_qwen2\",\n",
      "    \"unsloth_fixed\": true\n",
      "  },\n",
      "  \"base_model_name_or_path\": \"unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit\",\n",
      "  \"bias\": \"none\",\n",
      "  \"corda_config\": null,\n",
      "  \"ensure_weight_tying\": false,\n",
      "  \"eva_config\": null,\n",
      "  \"exclude_modules\": null,\n",
      "  \"fan_in_fan_out\": false,\n",
      "  \"inference_mode\": true,\n",
      "  \"init_lora_weights\": true,\n",
      "  \"layer_replication\": null,\n",
      "  \"layers_pattern\": null,\n",
      "  \"layers_to_transform\": null,\n",
      "  \"loftq_config\": {},\n",
      "  \"lora_alpha\": 32,\n",
      "  \"lora_bias\": false,\n",
      "  \"lora_dropout\": 0,\n",
      "  \"megatron_config\": null,\n",
      "  \"megatron_core\": \"megatron.core\",\n",
      "  \"modules_to_save\": null,\n",
      "  \"peft_type\": \"LORA\",\n",
      "  \"peft_version\": \"0.18.1\",\n",
      "  \"qalora_group_size\": 16,\n",
      "  \"r\": 16,\n",
      "  \"rank_pattern\": {},\n",
      "  \"revision\": null,\n",
      "  \"target_modules\": [\n",
      "    \"v_proj\",\n",
      "    \"down_proj\",\n",
      "    \"q_proj\",\n",
      "    \"gate_proj\",\n",
      "    \"o_proj\",\n",
      "    \"k_proj\",\n",
      "    \"up_proj\"\n",
      "  ],\n",
      "  \"target_parameters\": null,\n",
      "  \"task_type\": \"CAUSAL_LM\",\n",
      "  \"trainable_token_indices\": null,\n",
      "  \"use_dora\": false,\n",
      "  \"use_qalora\": false,\n",
      "  \"use_rslora\": false\n",
      "}"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python --force-reinstall --no-cache-dir\n",
    "!ls -la \"/content/drive/MyDrive/outputs/detective-qwen-sft\"\n",
    "!cat \"/content/drive/MyDrive/outputs/detective-qwen-sft/adapter_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8903,
     "status": "ok",
     "timestamp": 1771191237876,
     "user": {
      "displayName": "Carlo Carlo",
      "userId": "11471837763026793486"
     },
     "user_tz": -60
    },
    "id": "4sgKZN4RdpHr",
    "outputId": "2ef113e8-730b-4037-91a7-32d53f601428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ Initializing gguf converting session...\n",
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "2026-02-28 19:01:16.390873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1772305276.412558   15031 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1772305276.420003   15031 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1772305276.440644   15031 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1772305276.440669   15031 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1772305276.440674   15031 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1772305276.440678   15031 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "Last modified [/content/drive/MyDrive/scripts/export_to_gguf.py]: 2026-02-28 19:00:39\n",
      "Loading base + LoRA in one step...\n",
      "==((====))==  Unsloth 2026.2.1: Fast Qwen2 patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.563 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.35. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Loading checkpoint shards: 100% 2/2 [00:28<00:00, 14.19s/it]\n",
      "unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit does not have a padding token! Will use pad_token = <|vision_pad|>.\n",
      "Unsloth 2026.2.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n",
      "Merging LoRA into base model...\n",
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py:397: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n",
      "Saving merged full model...\n",
      "Saving to GGUF ...\n",
      "Unsloth: Merging model weights to 16-bit format...\n",
      "/usr/local/lib/python3.12/dist-packages/unsloth_zoo/saving_utils.py:1678: UserWarning: Model is not a PeftModel (no Lora adapters detected). Skipping Merge. Please use save_pretrained() or push_to_hub() instead!\n",
      "  warnings.warn(\"Model is not a PeftModel (no Lora adapters detected). Skipping Merge. Please use save_pretrained() or push_to_hub() instead!\")\n",
      "Unsloth: Converting to GGUF format...\n",
      "==((====))==  Unsloth: Conversion from HF to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF f16 might take 3 minutes.\n",
      "\\        /    [2] Converting GGUF f16 to ['q5_k_m'] might take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: llama.cpp found in the system. Skipping installation.\n",
      "Unsloth: Preparing converter script...\n",
      "[unsloth_zoo.llama_cpp|WARNING]Unsloth: Qwen2MoE num_experts patch target not found.\n",
      "Unsloth: [1] Converting model into f16 GGUF format.\n",
      "This might take 3 minutes...\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/unsloth_zoo/llama_cpp.py\", line 1038, in convert_to_gguf\n",
      "    subprocess.run(command, shell=True, check=True, capture_output=True)\n",
      "  File \"/usr/lib/python3.12/subprocess.py\", line 571, in run\n",
      "    raise CalledProcessError(retcode, process.args,\n",
      "subprocess.CalledProcessError: Command 'python llama.cpp/unsloth_convert_hf_to_gguf.py --outfile qwen2.5-7b-instruct.F16.gguf --outtype f16 --split-max-size 50G /content/drive/MyDrive/models/detective-qwen-gguf' returned non-zero exit status 1.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/unsloth/save.py\", line 1987, in unsloth_save_pretrained_gguf\n",
      "    all_file_locations, want_full_precision, is_vlm_update = save_to_gguf(\n",
      "                                                             ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/unsloth/save.py\", line 1229, in save_to_gguf\n",
      "    initial_files, is_vlm_update = convert_to_gguf(\n",
      "                                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/unsloth_zoo/llama_cpp.py\", line 1042, in convert_to_gguf\n",
      "    raise RuntimeError(f\"Unsloth: Failed to convert {description} to GGUF: {e}\")\n",
      "RuntimeError: Unsloth: Failed to convert model to GGUF: Command 'python llama.cpp/unsloth_convert_hf_to_gguf.py --outfile qwen2.5-7b-instruct.F16.gguf --outtype f16 --split-max-size 50G /content/drive/MyDrive/models/detective-qwen-gguf' returned non-zero exit status 1.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/scripts/export_to_gguf.py\", line 46, in <module>\n",
      "    model.save_pretrained_gguf(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/unsloth/save.py\", line 2007, in unsloth_save_pretrained_gguf\n",
      "    raise RuntimeError(f\"Unsloth: GGUF conversion failed: {e}\")\n",
      "RuntimeError: Unsloth: GGUF conversion failed: Unsloth: Failed to convert model to GGUF: Command 'python llama.cpp/unsloth_convert_hf_to_gguf.py --outfile qwen2.5-7b-instruct.F16.gguf --outtype f16 --split-max-size 50G /content/drive/MyDrive/models/detective-qwen-gguf' returned non-zero exit status 1.\n",
      "\n",
      "========================================\n",
      "ğŸ GGUF CONVERSION COMPLETE\n",
      "â±ï¸ Total Time: 3.66 minutes\n",
      "ğŸ“‚ Output Location: /content/drive/MyDrive/outputs/detective-qwen-gguf\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "# Force memory management fixes before running the script\n",
    "os.environ[\"PYTORCH_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "# Force torch to avoid using the broken dynamo compiler\n",
    "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
    "\n",
    "script_path = \"/content/drive/MyDrive/scripts/export_to_gguf.py\"\n",
    "\n",
    "print(\"ğŸ¬ Initializing gguf converting session...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Run the training script\n",
    "!python {script_path}\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_mins = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"\\n\" + \"=\"*40)\n",
    "print(f\"ğŸ GGUF CONVERSION COMPLETE\")\n",
    "print(f\"â±ï¸ Total Time: {elapsed_mins:.2f} minutes\")\n",
    "print(f\"ğŸ“‚ Output Location: /content/drive/MyDrive/outputs/detective-qwen-gguf\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 11.4.0\n",
      "-- The CXX compiler identification is GNU 11.4.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
      "-- The ASM compiler identification is GNU\n",
      "-- Found assembler: /usr/bin/cc\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "-- Found Threads: TRUE\n",
      "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
      "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
      "-- GGML_SYSTEM_ARCH: x86\n",
      "-- Including CPU backend\n",
      "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
      "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
      "-- Found OpenMP: TRUE (found version \"4.5\")\n",
      "-- x86 detected\n",
      "-- Adding CPU backend variant ggml-cpu: -march=native \n",
      "-- Found CUDAToolkit: /usr/local/cuda/targets/x86_64-linux/include (found version \"12.8.93\")\n",
      "-- CUDA Toolkit found\n",
      "-- The CUDA compiler identification is NVIDIA 12.8.93 with host compiler GNU 11.4.0\n",
      "-- Detecting CUDA compiler ABI info\n",
      "-- Detecting CUDA compiler ABI info - done\n",
      "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
      "-- Detecting CUDA compile features\n",
      "-- Detecting CUDA compile features - done\n",
      "-- Using CMAKE_CUDA_ARCHITECTURES=75-real CMAKE_CUDA_ARCHITECTURES_NATIVE=75-real\n",
      "-- CUDA host compiler is GNU 11.4.0\n",
      "-- Including CUDA backend\n",
      "-- ggml version: 0.9.7\n",
      "-- ggml commit:  05728db18\n",
      "-- Found OpenSSL: /usr/lib/x86_64-linux-gnu/libcrypto.so (found version \"3.0.2\")\n",
      "-- Performing Test OPENSSL_VERSION_SUPPORTED\n",
      "-- Performing Test OPENSSL_VERSION_SUPPORTED - Success\n",
      "-- OpenSSL found: 3.0.2\n",
      "-- Generating embedded license file for target: common\n",
      "-- Configuring done (11.6s)\n",
      "-- Generating done (0.3s)\n",
      "-- Build files have been written to: /content/llama.cpp/build\n",
      "[  0%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\n",
      "[  0%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o\n",
      "[  0%] Built target build_info\n",
      "[  0%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o\n",
      "[  0%] Building CXX object vendor/cpp-httplib/CMakeFiles/cpp-httplib.dir/httplib.cpp.o\n",
      "[  0%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\n",
      "[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\n",
      "[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\n",
      "[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\n",
      "[  1%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\n",
      "[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\n",
      "[  1%] Linking CXX shared library ../../bin/libggml-base.so\n",
      "[  1%] Built target ggml-base\n",
      "[  1%] Building C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o\n",
      "[  1%] Built target sha256\n",
      "[  2%] Building C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o\n",
      "[  2%] Built target xxhash\n",
      "[  2%] Building C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o\n",
      "[  2%] Built target sha1\n",
      "[  2%] Building CXX object tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o\n",
      "[  2%] Linking CXX executable ../../bin/llama-llava-cli\n",
      "[  2%] Built target llama-llava-cli\n",
      "[  2%] Building CXX object tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o\n",
      "[  3%] Linking CXX executable ../../bin/llama-gemma3-cli\n",
      "[  3%] Built target llama-gemma3-cli\n",
      "[  3%] Building CXX object tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o\n",
      "[  3%] Linking CXX executable ../../bin/llama-minicpmv-cli\n",
      "[  3%] Built target llama-minicpmv-cli\n",
      "[  3%] Building CXX object tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o\n",
      "[  4%] Linking CXX executable ../../bin/llama-qwen2vl-cli\n",
      "[  4%] Built target llama-qwen2vl-cli\n",
      "[  4%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\n",
      "[  5%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/add-id.cu.o\n",
      "[  5%] Linking CXX static library libcpp-httplib.a\n",
      "[  5%] Built target cpp-httplib\n",
      "[  6%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\n",
      "[  6%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\n",
      "[  6%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o\n",
      "[  6%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o\n",
      "[  6%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o\n",
      "[  6%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o\n",
      "[  6%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o\n",
      "[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o\n",
      "[  7%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o\n",
      "[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\n",
      "[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\n",
      "[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o\n",
      "[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o\n",
      "[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o\n",
      "[  8%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o\n",
      "[  8%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o\n",
      "[  8%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o\n",
      "[  8%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o\n",
      "[  8%] Linking CXX shared library ../../bin/libggml-cpu.so\n",
      "[  8%] Built target ggml-cpu\n",
      "[  8%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o\n",
      "[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o\n",
      "[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o\n",
      "[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o\n",
      "[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-dw.cu.o\n",
      "[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-transpose.cu.o\n",
      "[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d.cu.o\n",
      "[ 10%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o\n",
      "[ 10%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o\n",
      "[ 10%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o\n",
      "[ 10%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o\n",
      "[ 10%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cumsum.cu.o\n",
      "[ 10%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diag.cu.o\n",
      "[ 11%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o\n",
      "[ 11%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile.cu.o\n",
      "[ 11%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o\n",
      "[ 11%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o\n",
      "[ 11%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fill.cu.o\n",
      "[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o\n",
      "[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o\n",
      "[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/gla.cu.o\n",
      "[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o\n",
      "[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mean.cu.o\n",
      "[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmf.cu.o\n",
      "[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmid.cu.o\n",
      "[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o\n",
      "[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvf.cu.o\n",
      "[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o\n",
      "[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o\n",
      "[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o\n",
      "[ 14%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-sgd.cu.o\n",
      "[ 14%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o\n",
      "[ 14%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o\n",
      "[ 14%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad_reflect_1d.cu.o\n",
      "[ 14%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o\n",
      "[ 15%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o\n",
      "[ 15%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/roll.cu.o\n",
      "[ 15%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o\n",
      "[ 15%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o\n",
      "[ 15%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/set-rows.cu.o\n",
      "[ 15%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/set.cu.o\n",
      "[ 16%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softcap.cu.o\n",
      "[ 16%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o\n",
      "[ 16%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/solve_tri.cu.o\n",
      "[ 16%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-conv.cu.o\n",
      "[ 16%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-scan.cu.o\n",
      "[ 17%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o\n",
      "[ 17%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o\n",
      "[ 17%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/top-k.cu.o\n",
      "[ 17%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/topk-moe.cu.o\n",
      "[ 17%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tri.cu.o\n",
      "[ 17%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o\n",
      "[ 18%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o\n",
      "[ 18%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o\n",
      "[ 18%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv.cu.o\n",
      "[ 18%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-tile-instance-dkq112-dv112.cu.o\n",
      "[ 18%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-tile-instance-dkq128-dv128.cu.o\n",
      "[ 18%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-tile-instance-dkq256-dv256.cu.o\n",
      "[ 19%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-tile-instance-dkq40-dv40.cu.o\n",
      "[ 19%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-tile-instance-dkq576-dv512.cu.o\n",
      "[ 19%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-tile-instance-dkq64-dv64.cu.o\n",
      "[ 19%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-tile-instance-dkq72-dv72.cu.o\n",
      "[ 19%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-tile-instance-dkq80-dv80.cu.o\n",
      "[ 20%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-tile-instance-dkq96-dv96.cu.o\n",
      "[ 20%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu.o\n",
      "[ 20%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_32.cu.o\n",
      "[ 20%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o\n",
      "[ 20%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o\n",
      "[ 20%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o\n",
      "[ 21%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o\n",
      "[ 21%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu.o\n",
      "[ 21%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_32.cu.o\n",
      "[ 21%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o\n",
      "[ 21%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o\n",
      "[ 21%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o\n",
      "[ 22%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o\n",
      "[ 22%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu.o\n",
      "[ 22%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o\n",
      "[ 22%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o\n",
      "[ 22%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o\n",
      "[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o\n",
      "[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o\n",
      "[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o\n",
      "[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o\n",
      "[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o\n",
      "[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o\n",
      "[ 24%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o\n",
      "[ 24%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o\n",
      "[ 24%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o\n",
      "[ 24%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o\n",
      "[ 24%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o\n",
      "[ 24%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o\n",
      "[ 25%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o\n",
      "[ 25%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-mxfp4.cu.o\n",
      "[ 25%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o\n",
      "[ 25%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o\n",
      "[ 25%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o\n",
      "[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o\n",
      "[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o\n",
      "[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o\n",
      "[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o\n",
      "[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o\n",
      "[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o\n",
      "[ 27%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o\n",
      "[ 27%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_1.cu.o\n",
      "[ 27%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_10.cu.o\n",
      "[ 27%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_11.cu.o\n",
      "[ 27%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_12.cu.o\n",
      "[ 27%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_13.cu.o\n",
      "[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_14.cu.o\n",
      "[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_15.cu.o\n",
      "[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_16.cu.o\n",
      "[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_2.cu.o\n",
      "[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_3.cu.o\n",
      "[ 29%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_4.cu.o\n",
      "[ 29%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_5.cu.o\n",
      "[ 29%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_6.cu.o\n",
      "[ 29%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_7.cu.o\n",
      "[ 29%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_8.cu.o\n",
      "[ 29%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_9.cu.o\n",
      "[ 30%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-instance-q4_0-q4_0.cu.o\n",
      "[ 30%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-instance-q8_0-q8_0.cu.o\n",
      "[ 30%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-instance-f16-f16.cu.o\n",
      "[ 30%] Linking CUDA shared library ../../../bin/libggml-cuda.so\n",
      "[ 30%] Built target ggml-cuda\n",
      "[ 31%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-dl.cpp.o\n",
      "[ 31%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\n",
      "[ 31%] Linking CXX shared library ../../bin/libggml.so\n",
      "[ 31%] Built target ggml\n",
      "[ 31%] Building CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o\n",
      "[ 32%] Building CXX object src/CMakeFiles/llama.dir/llama.cpp.o\n",
      "[ 33%] Linking CXX executable ../../bin/llama-gguf-hash\n",
      "[ 33%] Built target llama-gguf-hash\n",
      "[ 33%] Building CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o\n",
      "[ 33%] Building CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o\n",
      "[ 33%] Building CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o\n",
      "[ 33%] Linking CXX executable ../../bin/llama-gguf\n",
      "[ 33%] Built target llama-gguf\n",
      "[ 33%] Building CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o\n",
      "[ 33%] Building CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o\n",
      "[ 34%] Building CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o\n",
      "[ 34%] Building CXX object src/CMakeFiles/llama.dir/llama-cparams.cpp.o\n",
      "[ 34%] Building CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o\n",
      "[ 34%] Building CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o\n",
      "[ 34%] Building CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o\n",
      "[ 34%] Building CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o\n",
      "[ 35%] Building CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o\n",
      "[ 35%] Building CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o\n",
      "[ 35%] Building CXX object src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o\n",
      "[ 35%] Building CXX object src/CMakeFiles/llama.dir/llama-memory.cpp.o\n",
      "[ 35%] Building CXX object src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o\n",
      "[ 35%] Building CXX object src/CMakeFiles/llama.dir/llama-memory-hybrid-iswa.cpp.o\n",
      "[ 36%] Building CXX object src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o\n",
      "[ 36%] Building CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o\n",
      "[ 36%] Building CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o\n",
      "[ 36%] Building CXX object src/CMakeFiles/llama.dir/llama-model-saver.cpp.o\n",
      "[ 36%] Building CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o\n",
      "[ 37%] Building CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o\n",
      "[ 37%] Building CXX object src/CMakeFiles/llama.dir/llama-sampler.cpp.o\n",
      "[ 37%] Building CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o\n",
      "[ 37%] Building CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o\n",
      "[ 37%] Building CXX object src/CMakeFiles/llama.dir/unicode.cpp.o\n",
      "[ 37%] Building CXX object src/CMakeFiles/llama.dir/models/afmoe.cpp.o\n",
      "[ 38%] Building CXX object src/CMakeFiles/llama.dir/models/apertus.cpp.o\n",
      "[ 38%] Building CXX object src/CMakeFiles/llama.dir/models/arcee.cpp.o\n",
      "[ 38%] Building CXX object src/CMakeFiles/llama.dir/models/arctic.cpp.o\n",
      "[ 38%] Building CXX object src/CMakeFiles/llama.dir/models/arwkv7.cpp.o\n",
      "[ 38%] Building CXX object src/CMakeFiles/llama.dir/models/baichuan.cpp.o\n",
      "[ 39%] Building CXX object src/CMakeFiles/llama.dir/models/bailingmoe.cpp.o\n",
      "[ 39%] Building CXX object src/CMakeFiles/llama.dir/models/bailingmoe2.cpp.o\n",
      "[ 39%] Building CXX object src/CMakeFiles/llama.dir/models/bert.cpp.o\n",
      "[ 39%] Building CXX object src/CMakeFiles/llama.dir/models/bitnet.cpp.o\n",
      "[ 39%] Building CXX object src/CMakeFiles/llama.dir/models/bloom.cpp.o\n",
      "[ 39%] Building CXX object src/CMakeFiles/llama.dir/models/chameleon.cpp.o\n",
      "[ 40%] Building CXX object src/CMakeFiles/llama.dir/models/chatglm.cpp.o\n",
      "[ 40%] Building CXX object src/CMakeFiles/llama.dir/models/codeshell.cpp.o\n",
      "[ 40%] Building CXX object src/CMakeFiles/llama.dir/models/cogvlm.cpp.o\n",
      "[ 40%] Building CXX object src/CMakeFiles/llama.dir/models/cohere2-iswa.cpp.o\n",
      "[ 40%] Building CXX object src/CMakeFiles/llama.dir/models/command-r.cpp.o\n",
      "[ 40%] Building CXX object src/CMakeFiles/llama.dir/models/dbrx.cpp.o\n",
      "[ 41%] Building CXX object src/CMakeFiles/llama.dir/models/deci.cpp.o\n",
      "[ 41%] Building CXX object src/CMakeFiles/llama.dir/models/deepseek.cpp.o\n",
      "[ 41%] Building CXX object src/CMakeFiles/llama.dir/models/deepseek2.cpp.o\n",
      "[ 41%] Building CXX object src/CMakeFiles/llama.dir/models/delta-net-base.cpp.o\n",
      "[ 41%] Building CXX object src/CMakeFiles/llama.dir/models/dots1.cpp.o\n",
      "[ 42%] Building CXX object src/CMakeFiles/llama.dir/models/dream.cpp.o\n",
      "[ 42%] Building CXX object src/CMakeFiles/llama.dir/models/ernie4-5-moe.cpp.o\n",
      "[ 42%] Building CXX object src/CMakeFiles/llama.dir/models/ernie4-5.cpp.o\n",
      "[ 42%] Building CXX object src/CMakeFiles/llama.dir/models/eurobert.cpp.o\n",
      "[ 42%] Building CXX object src/CMakeFiles/llama.dir/models/exaone-moe.cpp.o\n",
      "[ 42%] Building CXX object src/CMakeFiles/llama.dir/models/exaone.cpp.o\n",
      "[ 43%] Building CXX object src/CMakeFiles/llama.dir/models/exaone4.cpp.o\n",
      "[ 43%] Building CXX object src/CMakeFiles/llama.dir/models/falcon-h1.cpp.o\n",
      "[ 43%] Building CXX object src/CMakeFiles/llama.dir/models/falcon.cpp.o\n",
      "[ 43%] Building CXX object src/CMakeFiles/llama.dir/models/gemma-embedding.cpp.o\n",
      "[ 43%] Building CXX object src/CMakeFiles/llama.dir/models/gemma.cpp.o\n",
      "[ 43%] Building CXX object src/CMakeFiles/llama.dir/models/gemma2-iswa.cpp.o\n",
      "[ 44%] Building CXX object src/CMakeFiles/llama.dir/models/gemma3.cpp.o\n",
      "[ 44%] Building CXX object src/CMakeFiles/llama.dir/models/gemma3n-iswa.cpp.o\n",
      "[ 44%] Building CXX object src/CMakeFiles/llama.dir/models/glm4-moe.cpp.o\n",
      "[ 44%] Building CXX object src/CMakeFiles/llama.dir/models/glm4.cpp.o\n",
      "[ 44%] Building CXX object src/CMakeFiles/llama.dir/models/gpt2.cpp.o\n",
      "[ 45%] Building CXX object src/CMakeFiles/llama.dir/models/gptneox.cpp.o\n",
      "[ 45%] Building CXX object src/CMakeFiles/llama.dir/models/granite-hybrid.cpp.o\n",
      "[ 45%] Building CXX object src/CMakeFiles/llama.dir/models/granite.cpp.o\n",
      "[ 45%] Building CXX object src/CMakeFiles/llama.dir/models/grok.cpp.o\n",
      "[ 45%] Building CXX object src/CMakeFiles/llama.dir/models/grovemoe.cpp.o\n",
      "[ 45%] Building CXX object src/CMakeFiles/llama.dir/models/hunyuan-dense.cpp.o\n",
      "[ 46%] Building CXX object src/CMakeFiles/llama.dir/models/hunyuan-moe.cpp.o\n",
      "[ 46%] Building CXX object src/CMakeFiles/llama.dir/models/internlm2.cpp.o\n",
      "[ 46%] Building CXX object src/CMakeFiles/llama.dir/models/jais.cpp.o\n",
      "[ 46%] Building CXX object src/CMakeFiles/llama.dir/models/jais2.cpp.o\n",
      "[ 46%] Building CXX object src/CMakeFiles/llama.dir/models/jamba.cpp.o\n",
      "[ 46%] Building CXX object src/CMakeFiles/llama.dir/models/kimi-linear.cpp.o\n",
      "[ 47%] Building CXX object src/CMakeFiles/llama.dir/models/lfm2.cpp.o\n",
      "[ 47%] Building CXX object src/CMakeFiles/llama.dir/models/llada-moe.cpp.o\n",
      "[ 47%] Building CXX object src/CMakeFiles/llama.dir/models/llada.cpp.o\n",
      "[ 47%] Building CXX object src/CMakeFiles/llama.dir/models/llama-iswa.cpp.o\n",
      "[ 47%] Building CXX object src/CMakeFiles/llama.dir/models/llama.cpp.o\n",
      "[ 48%] Building CXX object src/CMakeFiles/llama.dir/models/maincoder.cpp.o\n",
      "[ 48%] Building CXX object src/CMakeFiles/llama.dir/models/mamba-base.cpp.o\n",
      "[ 48%] Building CXX object src/CMakeFiles/llama.dir/models/mamba.cpp.o\n",
      "[ 48%] Building CXX object src/CMakeFiles/llama.dir/models/mimo2-iswa.cpp.o\n",
      "[ 48%] Building CXX object src/CMakeFiles/llama.dir/models/minicpm3.cpp.o\n",
      "[ 48%] Building CXX object src/CMakeFiles/llama.dir/models/minimax-m2.cpp.o\n",
      "[ 49%] Building CXX object src/CMakeFiles/llama.dir/models/mistral3.cpp.o\n",
      "[ 49%] Building CXX object src/CMakeFiles/llama.dir/models/modern-bert.cpp.o\n",
      "[ 49%] Building CXX object src/CMakeFiles/llama.dir/models/mpt.cpp.o\n",
      "[ 49%] Building CXX object src/CMakeFiles/llama.dir/models/nemotron-h.cpp.o\n",
      "[ 49%] Building CXX object src/CMakeFiles/llama.dir/models/nemotron.cpp.o\n",
      "[ 49%] Building CXX object src/CMakeFiles/llama.dir/models/neo-bert.cpp.o\n",
      "[ 50%] Building CXX object src/CMakeFiles/llama.dir/models/olmo.cpp.o\n",
      "[ 50%] Building CXX object src/CMakeFiles/llama.dir/models/olmo2.cpp.o\n",
      "[ 50%] Building CXX object src/CMakeFiles/llama.dir/models/olmoe.cpp.o\n",
      "[ 50%] Building CXX object src/CMakeFiles/llama.dir/models/openai-moe-iswa.cpp.o\n",
      "[ 50%] Building CXX object src/CMakeFiles/llama.dir/models/openelm.cpp.o\n",
      "[ 51%] Building CXX object src/CMakeFiles/llama.dir/models/orion.cpp.o\n",
      "[ 51%] Building CXX object src/CMakeFiles/llama.dir/models/paddleocr.cpp.o\n",
      "[ 51%] Building CXX object src/CMakeFiles/llama.dir/models/pangu-embedded.cpp.o\n",
      "[ 51%] Building CXX object src/CMakeFiles/llama.dir/models/phi2.cpp.o\n",
      "[ 51%] Building CXX object src/CMakeFiles/llama.dir/models/phi3.cpp.o\n",
      "[ 51%] Building CXX object src/CMakeFiles/llama.dir/models/plamo.cpp.o\n",
      "[ 52%] Building CXX object src/CMakeFiles/llama.dir/models/plamo2.cpp.o\n",
      "[ 52%] Building CXX object src/CMakeFiles/llama.dir/models/plamo3.cpp.o\n",
      "[ 52%] Building CXX object src/CMakeFiles/llama.dir/models/plm.cpp.o\n",
      "[ 52%] Building CXX object src/CMakeFiles/llama.dir/models/qwen.cpp.o\n",
      "[ 52%] Building CXX object src/CMakeFiles/llama.dir/models/qwen2.cpp.o\n",
      "[ 52%] Building CXX object src/CMakeFiles/llama.dir/models/qwen2moe.cpp.o\n",
      "[ 53%] Building CXX object src/CMakeFiles/llama.dir/models/qwen2vl.cpp.o\n",
      "[ 53%] Building CXX object src/CMakeFiles/llama.dir/models/qwen3.cpp.o\n",
      "[ 53%] Building CXX object src/CMakeFiles/llama.dir/models/qwen35.cpp.o\n",
      "[ 53%] Building CXX object src/CMakeFiles/llama.dir/models/qwen35moe.cpp.o\n",
      "[ 53%] Building CXX object src/CMakeFiles/llama.dir/models/qwen3moe.cpp.o\n",
      "[ 54%] Building CXX object src/CMakeFiles/llama.dir/models/qwen3next.cpp.o\n",
      "[ 54%] Building CXX object src/CMakeFiles/llama.dir/models/qwen3vl-moe.cpp.o\n",
      "[ 54%] Building CXX object src/CMakeFiles/llama.dir/models/qwen3vl.cpp.o\n",
      "[ 54%] Building CXX object src/CMakeFiles/llama.dir/models/refact.cpp.o\n",
      "[ 54%] Building CXX object src/CMakeFiles/llama.dir/models/rnd1.cpp.o\n",
      "[ 54%] Building CXX object src/CMakeFiles/llama.dir/models/rwkv6-base.cpp.o\n",
      "[ 55%] Building CXX object src/CMakeFiles/llama.dir/models/rwkv6.cpp.o\n",
      "[ 55%] Building CXX object src/CMakeFiles/llama.dir/models/rwkv6qwen2.cpp.o\n",
      "[ 55%] Building CXX object src/CMakeFiles/llama.dir/models/rwkv7-base.cpp.o\n",
      "[ 55%] Building CXX object src/CMakeFiles/llama.dir/models/rwkv7.cpp.o\n",
      "[ 55%] Building CXX object src/CMakeFiles/llama.dir/models/seed-oss.cpp.o\n",
      "[ 55%] Building CXX object src/CMakeFiles/llama.dir/models/smallthinker.cpp.o\n",
      "[ 56%] Building CXX object src/CMakeFiles/llama.dir/models/smollm3.cpp.o\n",
      "[ 56%] Building CXX object src/CMakeFiles/llama.dir/models/stablelm.cpp.o\n",
      "[ 56%] Building CXX object src/CMakeFiles/llama.dir/models/starcoder.cpp.o\n",
      "[ 56%] Building CXX object src/CMakeFiles/llama.dir/models/starcoder2.cpp.o\n",
      "[ 56%] Building CXX object src/CMakeFiles/llama.dir/models/step35-iswa.cpp.o\n",
      "[ 57%] Building CXX object src/CMakeFiles/llama.dir/models/t5-dec.cpp.o\n",
      "[ 57%] Building CXX object src/CMakeFiles/llama.dir/models/t5-enc.cpp.o\n",
      "[ 57%] Building CXX object src/CMakeFiles/llama.dir/models/wavtokenizer-dec.cpp.o\n",
      "[ 57%] Building CXX object src/CMakeFiles/llama.dir/models/xverse.cpp.o\n",
      "[ 57%] Linking CXX shared library ../bin/libllama.so\n",
      "[ 57%] Built target llama\n",
      "[ 57%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o\n",
      "[ 57%] Building CXX object common/CMakeFiles/common.dir/arg.cpp.o\n",
      "[ 57%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-audio.cpp.o\n",
      "[ 57%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o\n",
      "[ 58%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o\n",
      "[ 58%] Building CXX object common/CMakeFiles/common.dir/chat-parser.cpp.o\n",
      "[ 58%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/cogvlm.cpp.o\n",
      "[ 58%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/conformer.cpp.o\n",
      "[ 58%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/glm4v.cpp.o\n",
      "[ 58%] Building CXX object common/CMakeFiles/common.dir/chat-parser-xml-toolcall.cpp.o\n",
      "[ 58%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/internvl.cpp.o\n",
      "[ 58%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/kimivl.cpp.o\n",
      "[ 59%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/kimik25.cpp.o\n",
      "[ 59%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/nemotron-v2-vl.cpp.o\n",
      "[ 59%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/llama4.cpp.o\n",
      "[ 59%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/llava.cpp.o\n",
      "[ 59%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/minicpmv.cpp.o\n",
      "[ 60%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/paddleocr.cpp.o\n",
      "[ 60%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/pixtral.cpp.o\n",
      "[ 60%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/qwen2vl.cpp.o\n",
      "[ 60%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/qwen3vl.cpp.o\n",
      "[ 60%] Building CXX object common/CMakeFiles/common.dir/chat-peg-parser.cpp.o\n",
      "[ 60%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/siglip.cpp.o\n",
      "[ 60%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/whisper-enc.cpp.o\n",
      "[ 61%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/mobilenetv5.cpp.o\n",
      "[ 62%] Building CXX object common/CMakeFiles/common.dir/chat.cpp.o\n",
      "[ 62%] Building CXX object tools/mtmd/CMakeFiles/mtmd.dir/models/youtuvl.cpp.o\n",
      "[ 62%] Linking CXX shared library ../../bin/libmtmd.so\n",
      "[ 62%] Built target mtmd\n",
      "[ 63%] Building C object tests/CMakeFiles/test-c.dir/test-c.c.o\n",
      "[ 63%] Linking C executable ../bin/test-c\n",
      "[ 63%] Built target test-c\n",
      "[ 63%] Building CXX object common/CMakeFiles/common.dir/common.cpp.o\n",
      "[ 64%] Building CXX object examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o\n",
      "[ 64%] Linking CXX executable ../../bin/llama-simple\n",
      "[ 64%] Built target llama-simple\n",
      "[ 64%] Building CXX object common/CMakeFiles/common.dir/console.cpp.o\n",
      "[ 64%] Building CXX object examples/simple-chat/CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o\n",
      "[ 64%] Linking CXX executable ../../bin/llama-simple-chat\n",
      "[ 64%] Built target llama-simple-chat\n",
      "[ 64%] Building CXX object common/CMakeFiles/common.dir/debug.cpp.o\n",
      "[ 64%] Building CXX object common/CMakeFiles/common.dir/download.cpp.o\n",
      "[ 64%] Building CXX object common/CMakeFiles/common.dir/json-partial.cpp.o\n",
      "[ 65%] Building CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o\n",
      "[ 65%] Building CXX object common/CMakeFiles/common.dir/llguidance.cpp.o\n",
      "[ 65%] Building CXX object common/CMakeFiles/common.dir/log.cpp.o\n",
      "[ 65%] Building CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o\n",
      "[ 65%] Building CXX object common/CMakeFiles/common.dir/ngram-map.cpp.o\n",
      "[ 66%] Building CXX object common/CMakeFiles/common.dir/ngram-mod.cpp.o\n",
      "[ 66%] Building CXX object common/CMakeFiles/common.dir/peg-parser.cpp.o\n",
      "[ 66%] Building CXX object common/CMakeFiles/common.dir/preset.cpp.o\n",
      "[ 66%] Building CXX object common/CMakeFiles/common.dir/regex-partial.cpp.o\n",
      "[ 66%] Building CXX object common/CMakeFiles/common.dir/sampling.cpp.o\n",
      "[ 66%] Building CXX object common/CMakeFiles/common.dir/speculative.cpp.o\n",
      "[ 67%] Building CXX object common/CMakeFiles/common.dir/unicode.cpp.o\n",
      "[ 67%] Building CXX object common/CMakeFiles/common.dir/jinja/lexer.cpp.o\n",
      "[ 67%] Building CXX object common/CMakeFiles/common.dir/jinja/parser.cpp.o\n",
      "[ 67%] Building CXX object common/CMakeFiles/common.dir/jinja/runtime.cpp.o\n",
      "[ 67%] Building CXX object common/CMakeFiles/common.dir/jinja/value.cpp.o\n",
      "[ 67%] Building CXX object common/CMakeFiles/common.dir/jinja/string.cpp.o\n",
      "[ 68%] Building CXX object common/CMakeFiles/common.dir/jinja/caps.cpp.o\n",
      "[ 68%] Building CXX object common/CMakeFiles/common.dir/__/license.cpp.o\n",
      "[ 68%] Linking CXX static library libcommon.a\n",
      "[ 68%] Built target common\n",
      "[ 68%] Building CXX object tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o\n",
      "[ 68%] Building CXX object tests/CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o\n",
      "[ 68%] Building CXX object tests/CMakeFiles/test-sampling.dir/get-model.cpp.o\n",
      "[ 68%] Linking CXX executable ../bin/test-sampling\n",
      "[ 69%] Linking CXX executable ../bin/test-tokenizer-0\n",
      "[ 69%] Built target test-sampling\n",
      "[ 69%] Building CXX object tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o\n",
      "[ 69%] Built target test-tokenizer-0\n",
      "[ 69%] Building CXX object tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o\n",
      "[ 69%] Building CXX object tests/CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o\n",
      "[ 69%] Linking CXX executable ../bin/test-grammar-parser\n",
      "[ 69%] Built target test-grammar-parser\n",
      "[ 70%] Building CXX object tests/CMakeFiles/test-grammar-integration.dir/get-model.cpp.o\n",
      "[ 70%] Building CXX object tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o\n",
      "[ 70%] Building CXX object tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o\n",
      "[ 70%] Linking CXX executable ../bin/test-llama-grammar\n",
      "[ 70%] Built target test-llama-grammar\n",
      "[ 70%] Building CXX object tests/CMakeFiles/test-chat.dir/test-chat.cpp.o\n",
      "[ 70%] Linking CXX executable ../bin/test-grammar-integration\n",
      "[ 70%] Built target test-grammar-integration\n",
      "[ 70%] Building CXX object tests/CMakeFiles/test-chat.dir/get-model.cpp.o\n",
      "[ 71%] Building CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o\n",
      "[ 71%] Building CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o\n",
      "[ 71%] Linking CXX executable ../bin/test-json-schema-to-grammar\n",
      "[ 71%] Built target test-json-schema-to-grammar\n",
      "[ 71%] Building CXX object tests/CMakeFiles/test-quantize-stats.dir/test-quantize-stats.cpp.o\n",
      "[ 72%] Linking CXX executable ../bin/test-quantize-stats\n",
      "[ 72%] Built target test-quantize-stats\n",
      "[ 72%] Building CXX object tests/CMakeFiles/test-gbnf-validator.dir/test-gbnf-validator.cpp.o\n",
      "[ 72%] Linking CXX executable ../bin/test-gbnf-validator\n",
      "[ 72%] Built target test-gbnf-validator\n",
      "[ 72%] Building CXX object tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o\n",
      "[ 72%] Linking CXX executable ../bin/test-tokenizer-1-bpe\n",
      "[ 72%] Built target test-tokenizer-1-bpe\n",
      "[ 72%] Building CXX object tests/CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o\n",
      "[ 72%] Linking CXX executable ../bin/test-tokenizer-1-spm\n",
      "[ 72%] Built target test-tokenizer-1-spm\n",
      "[ 72%] Building CXX object tests/CMakeFiles/test-chat-parser.dir/test-chat-parser.cpp.o\n",
      "[ 72%] Linking CXX executable ../bin/test-chat\n",
      "[ 72%] Built target test-chat\n",
      "[ 72%] Building CXX object tests/CMakeFiles/test-chat-peg-parser.dir/test-chat-peg-parser.cpp.o\n",
      "[ 73%] Building CXX object tests/CMakeFiles/test-chat-parser.dir/get-model.cpp.o\n",
      "[ 73%] Linking CXX executable ../bin/test-chat-parser\n",
      "[ 73%] Built target test-chat-parser\n",
      "[ 73%] Building CXX object tests/CMakeFiles/test-chat-peg-parser.dir/peg-parser/simple-tokenize.cpp.o\n",
      "[ 73%] Building CXX object tests/CMakeFiles/test-chat-peg-parser.dir/get-model.cpp.o\n",
      "[ 73%] Building CXX object tests/CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o\n",
      "[ 73%] Building CXX object tests/CMakeFiles/test-chat-template.dir/get-model.cpp.o\n",
      "[ 73%] Linking CXX executable ../bin/test-chat-template\n",
      "[ 73%] Built target test-chat-template\n",
      "[ 74%] Building CXX object tests/CMakeFiles/test-jinja.dir/test-jinja.cpp.o\n",
      "[ 75%] Linking CXX executable ../bin/test-chat-peg-parser\n",
      "[ 75%] Built target test-chat-peg-parser\n",
      "[ 75%] Building CXX object tests/CMakeFiles/test-json-partial.dir/test-json-partial.cpp.o\n",
      "[ 75%] Building CXX object tests/CMakeFiles/test-json-partial.dir/get-model.cpp.o\n",
      "[ 75%] Linking CXX executable ../bin/test-json-partial\n",
      "[ 75%] Built target test-json-partial\n",
      "[ 75%] Building CXX object tests/CMakeFiles/test-jinja.dir/get-model.cpp.o\n",
      "[ 76%] Building CXX object tests/CMakeFiles/test-log.dir/test-log.cpp.o\n",
      "[ 76%] Building CXX object tests/CMakeFiles/test-log.dir/get-model.cpp.o\n",
      "[ 76%] Linking CXX executable ../bin/test-log\n",
      "[ 76%] Built target test-log\n",
      "[ 76%] Building CXX object tests/CMakeFiles/test-peg-parser.dir/test-peg-parser.cpp.o\n",
      "[ 76%] Building CXX object tests/CMakeFiles/test-peg-parser.dir/peg-parser/simple-tokenize.cpp.o\n",
      "[ 76%] Building CXX object tests/CMakeFiles/test-peg-parser.dir/peg-parser/test-basic.cpp.o\n",
      "[ 76%] Linking CXX executable ../bin/test-jinja\n",
      "[ 76%] Built target test-jinja\n",
      "[ 76%] Building CXX object tests/CMakeFiles/test-peg-parser.dir/peg-parser/test-gbnf-generation.cpp.o\n",
      "[ 76%] Building CXX object tests/CMakeFiles/test-regex-partial.dir/test-regex-partial.cpp.o\n",
      "[ 76%] Building CXX object tests/CMakeFiles/test-regex-partial.dir/get-model.cpp.o\n",
      "[ 76%] Linking CXX executable ../bin/test-regex-partial\n",
      "[ 76%] Built target test-regex-partial\n",
      "[ 76%] Building CXX object tests/CMakeFiles/test-peg-parser.dir/peg-parser/test-json-parser.cpp.o\n",
      "[ 76%] Building CXX object tests/CMakeFiles/test-thread-safety.dir/test-thread-safety.cpp.o\n",
      "[ 77%] Building CXX object tests/CMakeFiles/test-peg-parser.dir/peg-parser/test-json-serialization.cpp.o\n",
      "[ 77%] Building CXX object tests/CMakeFiles/test-thread-safety.dir/get-model.cpp.o\n",
      "[ 77%] Linking CXX executable ../bin/test-thread-safety\n",
      "[ 77%] Built target test-thread-safety\n",
      "[ 77%] Building CXX object tests/CMakeFiles/test-peg-parser.dir/peg-parser/test-unicode.cpp.o\n",
      "[ 77%] Building CXX object tests/CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o\n",
      "[ 77%] Building CXX object tests/CMakeFiles/test-peg-parser.dir/get-model.cpp.o\n",
      "[ 77%] Linking CXX executable ../bin/test-peg-parser\n",
      "[ 77%] Built target test-peg-parser\n",
      "[ 77%] Building CXX object tests/CMakeFiles/test-opt.dir/test-opt.cpp.o\n",
      "[ 77%] Building CXX object tests/CMakeFiles/test-arg-parser.dir/get-model.cpp.o\n",
      "[ 77%] Linking CXX executable ../bin/test-arg-parser\n",
      "[ 77%] Building CXX object tests/CMakeFiles/test-opt.dir/get-model.cpp.o\n",
      "[ 78%] Linking CXX executable ../bin/test-opt\n",
      "[ 78%] Built target test-arg-parser\n",
      "[ 79%] Building CXX object tests/CMakeFiles/test-gguf.dir/test-gguf.cpp.o\n",
      "[ 79%] Built target test-opt\n",
      "[ 79%] Building CXX object tests/CMakeFiles/test-gguf.dir/get-model.cpp.o\n",
      "[ 79%] Building CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o\n",
      "[ 79%] Linking CXX executable ../bin/test-gguf\n",
      "[ 79%] Built target test-gguf\n",
      "[ 79%] Building CXX object tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o\n",
      "[ 79%] Building CXX object tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o\n",
      "[ 79%] Building CXX object tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o\n",
      "[ 80%] Linking CXX executable ../bin/test-model-load-cancel\n",
      "[ 80%] Built target test-model-load-cancel\n",
      "[ 80%] Building CXX object tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o\n",
      "[ 81%] Building CXX object tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o\n",
      "[ 81%] Linking CXX executable ../bin/test-autorelease\n",
      "[ 81%] Built target test-autorelease\n",
      "[ 82%] Building CXX object tests/CMakeFiles/test-backend-sampler.dir/test-backend-sampler.cpp.o\n",
      "[ 82%] Building CXX object tests/CMakeFiles/test-backend-sampler.dir/get-model.cpp.o\n",
      "[ 82%] Linking CXX executable ../bin/test-backend-sampler\n",
      "[ 82%] Built target test-backend-sampler\n",
      "[ 82%] Building CXX object tests/CMakeFiles/test-state-restore-fragmented.dir/test-state-restore-fragmented.cpp.o\n",
      "[ 83%] Building CXX object tests/CMakeFiles/test-state-restore-fragmented.dir/get-model.cpp.o\n",
      "[ 83%] Linking CXX executable ../bin/test-state-restore-fragmented\n",
      "[ 83%] Built target test-state-restore-fragmented\n",
      "[ 83%] Building CXX object tests/CMakeFiles/test-barrier.dir/test-barrier.cpp.o\n",
      "[ 83%] Building CXX object tests/CMakeFiles/test-barrier.dir/get-model.cpp.o\n",
      "[ 83%] Linking CXX executable ../bin/test-barrier\n",
      "[ 83%] Built target test-barrier\n",
      "[ 83%] Building CXX object tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o\n",
      "[ 84%] Building CXX object tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o\n",
      "[ 84%] Linking CXX executable ../bin/test-quantize-fns\n",
      "[ 84%] Built target test-quantize-fns\n",
      "[ 84%] Building CXX object tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o\n",
      "[ 84%] Building CXX object tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o\n",
      "[ 84%] Linking CXX executable ../bin/test-quantize-perf\n",
      "[ 84%] Built target test-quantize-perf\n",
      "[ 84%] Building CXX object tests/CMakeFiles/test-rope.dir/test-rope.cpp.o\n",
      "[ 84%] Building CXX object tests/CMakeFiles/test-rope.dir/get-model.cpp.o\n",
      "[ 85%] Linking CXX executable ../bin/test-rope\n",
      "[ 85%] Built target test-rope\n",
      "[ 85%] Building C object tests/CMakeFiles/test-mtmd-c-api.dir/test-mtmd-c-api.c.o\n",
      "[ 85%] Building CXX object tests/CMakeFiles/test-mtmd-c-api.dir/get-model.cpp.o\n",
      "[ 85%] Linking CXX executable ../bin/test-mtmd-c-api\n",
      "[ 85%] Built target test-mtmd-c-api\n",
      "[ 85%] Building CXX object tests/CMakeFiles/gguf-model-data.dir/gguf-model-data.cpp.o\n",
      "[ 85%] Linking CXX static library libgguf-model-data.a\n",
      "[ 85%] Built target gguf-model-data\n",
      "[ 85%] Building CXX object tests/CMakeFiles/test-alloc.dir/test-alloc.cpp.o\n",
      "[ 86%] Building CXX object tests/CMakeFiles/test-alloc.dir/get-model.cpp.o\n",
      "[ 86%] Linking CXX executable ../bin/test-alloc\n",
      "[ 86%] Built target test-alloc\n",
      "[ 86%] Building CXX object examples/batched/CMakeFiles/llama-batched.dir/batched.cpp.o\n",
      "[ 87%] Linking CXX executable ../../bin/llama-batched\n",
      "[ 87%] Built target llama-batched\n",
      "[ 87%] Building CXX object examples/debug/CMakeFiles/llama-debug.dir/debug.cpp.o\n",
      "[ 87%] Linking CXX executable ../bin/test-backend-ops\n",
      "[ 87%] Built target test-backend-ops\n",
      "[ 88%] Building CXX object examples/embedding/CMakeFiles/llama-embedding.dir/embedding.cpp.o\n",
      "[ 88%] Linking CXX executable ../../bin/llama-embedding\n",
      "[ 88%] Linking CXX executable ../../bin/llama-debug\n",
      "[ 88%] Built target llama-embedding\n",
      "[ 88%] Building CXX object examples/eval-callback/CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o\n",
      "[ 88%] Built target llama-debug\n",
      "[ 88%] Building CXX object examples/idle/CMakeFiles/llama-idle.dir/idle.cpp.o\n",
      "[ 88%] Linking CXX executable ../../bin/llama-idle\n",
      "[ 88%] Linking CXX executable ../../bin/llama-eval-callback\n",
      "[ 88%] Built target llama-idle\n",
      "[ 88%] Building CXX object examples/lookahead/CMakeFiles/llama-lookahead.dir/lookahead.cpp.o\n",
      "[ 88%] Built target llama-eval-callback\n",
      "[ 89%] Building CXX object examples/lookup/CMakeFiles/llama-lookup.dir/lookup.cpp.o\n",
      "[ 89%] Linking CXX executable ../../bin/llama-lookahead\n",
      "[ 89%] Linking CXX executable ../../bin/llama-lookup\n",
      "[ 89%] Built target llama-lookahead\n",
      "[ 89%] Building CXX object examples/lookup/CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o\n",
      "[ 89%] Built target llama-lookup\n",
      "[ 89%] Building CXX object examples/lookup/CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o\n",
      "[ 89%] Linking CXX executable ../../bin/llama-lookup-merge\n",
      "[ 89%] Built target llama-lookup-merge\n",
      "[ 90%] Building CXX object examples/lookup/CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o\n",
      "[ 90%] Linking CXX executable ../../bin/llama-lookup-create\n",
      "[ 90%] Built target llama-lookup-create\n",
      "[ 90%] Building CXX object examples/parallel/CMakeFiles/llama-parallel.dir/parallel.cpp.o\n",
      "[ 90%] Linking CXX executable ../../bin/llama-lookup-stats\n",
      "[ 90%] Built target llama-lookup-stats\n",
      "[ 90%] Building CXX object examples/passkey/CMakeFiles/llama-passkey.dir/passkey.cpp.o\n",
      "[ 90%] Linking CXX executable ../../bin/llama-parallel\n",
      "[ 90%] Built target llama-parallel\n",
      "[ 90%] Building CXX object examples/retrieval/CMakeFiles/llama-retrieval.dir/retrieval.cpp.o\n",
      "[ 90%] Linking CXX executable ../../bin/llama-passkey\n",
      "[ 90%] Built target llama-passkey\n",
      "[ 90%] Building CXX object examples/save-load-state/CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o\n",
      "[ 90%] Linking CXX executable ../../bin/llama-retrieval\n",
      "[ 90%] Linking CXX executable ../../bin/llama-save-load-state\n",
      "[ 90%] Built target llama-retrieval\n",
      "[ 90%] Building CXX object examples/speculative/CMakeFiles/llama-speculative.dir/speculative.cpp.o\n",
      "[ 90%] Built target llama-save-load-state\n",
      "[ 91%] Building CXX object examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o\n",
      "[ 91%] Linking CXX executable ../../bin/llama-speculative-simple\n",
      "[ 91%] Linking CXX executable ../../bin/llama-speculative\n",
      "[ 91%] Built target llama-speculative-simple\n",
      "[ 91%] Building CXX object examples/gen-docs/CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o\n",
      "[ 91%] Built target llama-speculative\n",
      "[ 91%] Building CXX object examples/training/CMakeFiles/llama-finetune.dir/finetune.cpp.o\n",
      "[ 91%] Linking CXX executable ../../bin/llama-gen-docs\n",
      "[ 91%] Linking CXX executable ../../bin/llama-finetune\n",
      "[ 91%] Built target llama-gen-docs\n",
      "[ 91%] Building CXX object examples/diffusion/CMakeFiles/llama-diffusion-cli.dir/diffusion-cli.cpp.o\n",
      "[ 91%] Built target llama-finetune\n",
      "[ 91%] Building CXX object examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o\n",
      "[ 91%] Linking CXX executable ../../bin/llama-convert-llama2c-to-ggml\n",
      "[ 91%] Built target llama-convert-llama2c-to-ggml\n",
      "[ 91%] Building CXX object pocs/vdot/CMakeFiles/llama-vdot.dir/vdot.cpp.o\n",
      "[ 91%] Linking CXX executable ../../bin/llama-vdot\n",
      "[ 91%] Built target llama-vdot\n",
      "[ 91%] Building CXX object pocs/vdot/CMakeFiles/llama-q8dot.dir/q8dot.cpp.o\n",
      "[ 91%] Linking CXX executable ../../bin/llama-diffusion-cli\n",
      "[ 91%] Built target llama-diffusion-cli\n",
      "[ 91%] Building CXX object tools/batched-bench/CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o\n",
      "[ 91%] Linking CXX executable ../../bin/llama-q8dot\n",
      "[ 91%] Built target llama-q8dot\n",
      "[ 91%] Building CXX object tools/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o\n",
      "[ 91%] Linking CXX executable ../../bin/llama-gguf-split\n",
      "[ 91%] Built target llama-gguf-split\n",
      "[ 92%] Building CXX object tools/imatrix/CMakeFiles/llama-imatrix.dir/imatrix.cpp.o\n",
      "[ 92%] Linking CXX executable ../../bin/llama-batched-bench\n",
      "[ 92%] Built target llama-batched-bench\n",
      "[ 92%] Building CXX object tools/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o\n",
      "[ 92%] Linking CXX executable ../../bin/llama-imatrix\n",
      "[ 92%] Built target llama-imatrix\n",
      "[ 92%] Building CXX object tools/completion/CMakeFiles/llama-completion.dir/completion.cpp.o\n",
      "[ 92%] Linking CXX executable ../../bin/llama-bench\n",
      "[ 92%] Built target llama-bench\n",
      "[ 92%] Building CXX object tools/perplexity/CMakeFiles/llama-perplexity.dir/perplexity.cpp.o\n",
      "[ 92%] Linking CXX executable ../../bin/llama-completion\n",
      "[ 92%] Built target llama-completion\n",
      "[ 92%] Building CXX object tools/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o\n",
      "[ 92%] Linking CXX executable ../../bin/llama-quantize\n",
      "[ 92%] Built target llama-quantize\n",
      "[ 92%] Building CXX object tools/server/CMakeFiles/server-context.dir/server-task.cpp.o\n",
      "[ 93%] Linking CXX executable ../../bin/llama-perplexity\n",
      "[ 93%] Built target llama-perplexity\n",
      "[ 93%] Building CXX object tools/server/CMakeFiles/server-context.dir/server-queue.cpp.o\n",
      "[ 94%] Building CXX object tools/server/CMakeFiles/server-context.dir/server-common.cpp.o\n",
      "[ 94%] Building CXX object tools/tokenize/CMakeFiles/llama-tokenize.dir/tokenize.cpp.o\n",
      "[ 94%] Linking CXX executable ../../bin/llama-tokenize\n",
      "[ 94%] Built target llama-tokenize\n",
      "[ 94%] Building CXX object tools/server/CMakeFiles/server-context.dir/server-context.cpp.o\n",
      "[ 94%] Building CXX object tools/tts/CMakeFiles/llama-tts.dir/tts.cpp.o\n",
      "[ 95%] Linking CXX executable ../../bin/llama-tts\n",
      "[ 95%] Built target llama-tts\n",
      "[ 95%] Building CXX object tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o\n",
      "[ 96%] Linking CXX executable ../../bin/llama-mtmd-cli\n",
      "[ 96%] Built target llama-mtmd-cli\n",
      "[ 97%] Building CXX object tools/cvector-generator/CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o\n",
      "[ 97%] Linking CXX executable ../../bin/llama-cvector-generator\n",
      "[ 97%] Built target llama-cvector-generator\n",
      "[ 97%] Building CXX object tools/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o\n",
      "[ 97%] Linking CXX static library libserver-context.a\n",
      "[ 97%] Built target server-context\n",
      "[ 97%] Building CXX object tools/fit-params/CMakeFiles/llama-fit-params.dir/fit-params.cpp.o\n",
      "[ 97%] Linking CXX executable ../../bin/llama-fit-params\n",
      "[ 98%] Linking CXX executable ../../bin/llama-export-lora\n",
      "[ 98%] Built target llama-fit-params\n",
      "[ 98%] Building CXX object tests/CMakeFiles/test-gguf-model-data.dir/test-gguf-model-data.cpp.o\n",
      "[ 98%] Built target llama-export-lora\n",
      "[ 99%] Building CXX object tools/cli/CMakeFiles/llama-cli.dir/cli.cpp.o\n",
      "[ 99%] Linking CXX executable ../bin/test-gguf-model-data\n",
      "[ 99%] Built target test-gguf-model-data\n",
      "[ 99%] Generating loading.html.hpp\n",
      "[100%] Generating index.html.gz.hpp\n",
      "[100%] Building CXX object tools/server/CMakeFiles/llama-server.dir/server.cpp.o\n",
      "[100%] Linking CXX executable ../../bin/llama-cli\n",
      "[100%] Built target llama-cli\n",
      "[100%] Building CXX object tools/server/CMakeFiles/llama-server.dir/server-http.cpp.o\n",
      "[100%] Building CXX object tools/server/CMakeFiles/llama-server.dir/server-models.cpp.o\n",
      "[100%] Linking CXX executable ../../bin/llama-server\n",
      "[100%] Built target llama-server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/content/llama.cpp'...\n",
      "CMAKE_BUILD_TYPE=Release\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf /content/llama.cpp\n",
    "git clone https://github.com/ggerganov/llama.cpp /content/llama.cpp\n",
    "cd /content/llama.cpp\n",
    "cmake -B build -DGGML_CUDA=ON\n",
    "cmake --build build --config Release -j$(nproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:hf-to-gguf:Loading model: detective-qwen-gguf\n",
      "INFO:hf-to-gguf:Model architecture: Qwen2ForCausalLM\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: indexing model part 'model-00001-of-00002.safetensors'\n",
      "INFO:hf-to-gguf:gguf: indexing model part 'model-00002-of-00002.safetensors'\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/llama.cpp/convert_hf_to_gguf.py\", line 12130, in <module>\n",
      "    main()\n",
      "  File \"/content/llama.cpp/convert_hf_to_gguf.py\", line 12124, in main\n",
      "    model_instance.write()\n",
      "  File \"/content/llama.cpp/convert_hf_to_gguf.py\", line 715, in write\n",
      "    self.prepare_tensors()\n",
      "  File \"/content/llama.cpp/convert_hf_to_gguf.py\", line 555, in prepare_tensors\n",
      "    self.dequant_model()\n",
      "  File \"/content/llama.cpp/convert_hf_to_gguf.py\", line 474, in dequant_model\n",
      "    raise NotImplementedError(f\"Quant method is not yet supported: {quant_method!r}\")\n",
      "NotImplementedError: Quant method is not yet supported: 'bitsandbytes'\n"
     ]
    }
   ],
   "source": [
    "!cp -r /content/llama.cpp /content/drive/MyDrive/TMP/llama.cpp\n",
    "!cd /content/llama.cpp && python3 convert_hf_to_gguf.py \\\n",
    "  \"/content/drive/MyDrive/models/detective-qwen-gguf\" \\\n",
    "  --outfile \"/content/drive/MyDrive/models/detective-qwen-gguf/detective-qwen.f16.gguf\" \\\n",
    "  --outtype f16 \\\n",
    "  --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a044bc22a513488fa6564ae925721c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75699d1f6454f89b57bdd51170f9622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9c9d9b6a8a4f529b072a5308582d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a891517cfd4614a25ad9b163c810a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11c6c04b5d84cc5967da809152c4a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259b288129bd415b8b2e68a8fb523d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d827af3af04494ac6cf49f178eeeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62a95640d86492bb3140a2ffe7f6752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc62ee5e5744a45bc0628c882bd627a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56bbe24833442878e14199b0ef21a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# 1. Paths\n",
    "base_model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "adapter_path = \"/content/drive/MyDrive/models/detective-qwen-gguf\" # Your current folder\n",
    "output_path = \"/content/detective-qwen-full-f16\"\n",
    "\n",
    "# 2. Load Base Model in Float16 (Crucial: DO NOT load in 4bit here)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# 3. Load your fine-tune and Merge\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "# 4. Save the \"Clean\" model\n",
    "merged_model.save_pretrained(output_path)\n",
    "tokenizer.save_pretrained(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /content/llama.cpp/convert_hf_to_gguf.py \\\n",
    "  /content/detective-qwen-full-f16 \\\n",
    "  --outfile /content/detective-qwen-q4_k_m.gguf \\\n",
    "  --outtype q4_k_m"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNj/C8zFI15+TQidkQb9Lvv",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
